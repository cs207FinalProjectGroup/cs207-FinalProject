{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pnV4Beaa5pLh"
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d879ijtt5pLn"
   },
   "source": [
    "Since Newton invented calculus, differentiating a function has been essential to the advancement of humanity. Calculating the derivative of a function is crucial to finding the extrema for a function and determining zeros for a function, two operations that are central to optimization (1). Often, we can find the symbolic/analytical solution to the derivative of a function, however this has become increasingly complex and computationally expensive as our functions/equations have grown in size and complexity. Numerically solving differential equations forms a cornerstone of modern science and engineering and is intimately linked with machine learning; however this method suffers from rounding errors and numerical instability. Many of these issues can be solved using Automatic Differentiation (AD) because AD can calculate the exact derivative up to machine precision (2). The logic and processes behind AD enables it to be implemented using computer code, making it easily accessible for use by scientists and mathematicians. This python package will implement the forward mode of AD. ​"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0A_s2Tiq5pLq"
   },
   "source": [
    "# How to use the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyGbNata5pLt"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGrxDmvK5pLw"
   },
   "source": [
    "Ideally, the user should have Anaconda installed (https://www.anaconda.com/download/).\n",
    "\n",
    "To install the package, a user will download or clone the repository onto their local machine. Then, the user can, but does not need to, create a virtual environment using virtualenv. If the user has Anaconda installed, then the user will already have virtualenv installed, but if they do not, the user can the user can run the following command in the terminal:\n",
    "\n",
    "    sudo easy_install virtualenv\n",
    "Then, to create a virtual environment, the user runs the following command in the terminal in the package directory:\n",
    "\n",
    "    virtualenv env\n",
    "To activate the virtual environment, the user runs the following command in the terminal in the package directory:\n",
    "\n",
    "    source env/bin/activate\n",
    "To deactivate the virtual environment, the user runs the following command in the terminal in the package directory:\n",
    "\n",
    "    deactivate\n",
    "Whether or not the user uses a virtual environment, they will need to make sure they have the necessary dependencies. In the package directory includes a requirements.txt file that lists the necessary dependencies. The user can easily install all the dependencies with the following command:\n",
    "\n",
    "    pip install -r requirements.txt\n",
    "After installing the necessary dependencies, the user can then start using the package in their code with an import statement such as\n",
    "\n",
    "    import autodiff as ad\n",
    "To run the tests for the package, the user can run the following command in terminal in the package folder:\n",
    "\n",
    "    pytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0taiOCzQ5pLz"
   },
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YWvClCF35pL3"
   },
   "source": [
    "\n",
    "\n",
    "For example, suppose $f(x, y) = x^2 + 2xy + y^2$, and $x = 1, y = 2$.\n",
    "​\n",
    "$\n",
    "f(1, 2) = 9\\\\\n",
    "\\frac{\\partial f}{\\partial x} = 2x + 2y \\implies \\frac{\\partial f}{\\partial x}|_{x = 1, y = 2} = 6 \\\\\n",
    "\\frac{\\partial f}{\\partial y} = 2x + 2y \\implies \\frac{\\partial f}{\\partial y}|_{x = 1, y = 2} = 6 \n",
    "$\n",
    "​\n",
    "\n",
    "\n",
    "To solve this problem using our package, the user will run the following straightforward code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbhnK3y68xp2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/blin/Documents/cs207/cs207-FinalProject\n"
     ]
    }
   ],
   "source": [
    "% cd ../\n",
    "#Ignore this. Used to import autodiff in the docs folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SExfkhvS8LDe"
   },
   "outputs": [],
   "source": [
    "import autodiff as ad\n",
    "\n",
    "# Define x and y scalars with variable name and value. The actual python variable names do not matter.\n",
    "x = ad.Scalar('x', 1)\n",
    "y = ad.Scalar('y', 2)\n",
    "# Express f in terms of x and y. User does not need to define any more scalar objects besides the basic ones x and y above. \n",
    "f = x ** 2 + 2 * x * y + y ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get value of f(1, 2)\n",
    "f.getValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get partial derivative with respect to x. Pass in variable names as String in list.\n",
    "f.getGradient(['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get partial derivative with respect to y\n",
    "f.getGradient(['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 6.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get both partial derivatives\n",
    "f.getGradient(['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 6.0, 'y': 6.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.getDeriv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LPAESup_72Im"
   },
   "source": [
    "\n",
    "With our package, users will be able to easily define functions that rely on variables and their derivatives. For example, consider Newton's method in finding roots: For a scalar function $f(x)$, we want to find the $x$ such that $f(x) = 0$. Newton's method states that we are able to find the root by updating from an intial `x_0` value with the update equation $x_{n} = x_{n-1} - \\frac{f(x_{n-1})}{f^{\\prime}(x_{n-1})} $ until we get an $x_n$ such that $f(x_n) \\approx 0$. With our package, the method can be written as the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "whFFa0Xm8ACf"
   },
   "outputs": [],
   "source": [
    "def newton_method(fn, init_x = 0, threshold = 1e-10):\n",
    "    # Initialize scalar with an init value\n",
    "    x = ad.Scalar('x', init_x)\n",
    "    y = fn(x)\n",
    "    # While f(x) is greater than threshold, update x.\n",
    "    while y.getValue() > threshold:\n",
    "        x = x - y.getValue() / y.getGradient('x')\n",
    "        y = fn(x)\n",
    "    # Return x such that f(x) approximately equals 0.\n",
    "    return x.getValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JT_FfHM5pL7"
   },
   "source": [
    "# Background\n",
    "​\n",
    "The following mathematical concepts and background are required for understanding automatic differentiation:\n",
    "​\n",
    "### 1. Differential calculus\n",
    "​\n",
    "Differential calculus is a subfield of calculus concerned with the study of the rates at which quantities change.\n",
    "For example, given the function: \n",
    "\\begin{align}\n",
    " f\\left(x\\right) &=  {x^{2}}     \n",
    " \\end{align}\n",
    " \n",
    " Increment x by h:\n",
    " \\begin{align}\n",
    " f\\left(x+h\\right) &=  {(x+h)^{2}}     \n",
    " \\end{align}\n",
    " \n",
    " Apply the finite difference approximation to calculate the slope:\n",
    "  \\begin{align}\n",
    " \\frac{f\\left(x+h\\right) - f\\left(x\\right) }{h}\n",
    " \\end{align}\n",
    " \n",
    "Simplify the equation:\n",
    "  \\begin{align}\n",
    " &= \\frac{x^{2}+2xh+h^{2}-x^{2} }{h}\\\\\n",
    " &= \\frac{2xh+h^{2}}{h}\\\\\n",
    " &=2x+h\n",
    " \\end{align}\n",
    " \n",
    " Set $h\\rightarrow 0$:\n",
    "   \\begin{align}\n",
    " 2x +0 &= 2x\n",
    "  \\end{align}\n",
    "  \n",
    "The derivative is then defined is:\n",
    "\\begin{align}\n",
    " \\lim_{h\\to0} \\frac{f\\left(x+h\\right) - f\\left(x\\right) }{h}\n",
    " \\end{align}\n",
    " \n",
    "### 2. Elementary functions and their derivatives\n",
    "\n",
    "|       Function $f(x)$                |       Derivative $f^{\\prime}(x)$                |\n",
    "| :-------------------:  | :------------------------------------------------------------------------------:  |\n",
    "| ${c}$           | $0$         |\n",
    "| ${x}$           | $1$         |\n",
    "| ${x^{n}}$           | ${nx^{n-1}}$         |\n",
    "| $\\frac{1}{x}$     | $\\frac{-1}{x^{2}}$     |\n",
    "| $ln{x}$     | $\\frac{1}{x}$     |\n",
    "| $\\sin(x)$           |   $\\cos(x)$         |\n",
    "| $\\cos(x)$           |   $-\\sin(x)$         |\n",
    "| $\\tan(x)$           |   $\\dfrac{1}{\\cos^2(x)}$         |\n",
    "| $\\exp(x)$           |   $\\exp(x)$         |\n",
    "| ${a^{x}}$           |   ${a^{x}\\ln{a}}$         |\n",
    " \n",
    "### 3. The chain rule$^{(1)}$\n",
    "\n",
    "For a function $h(u(t))$, the derivative of $h$ with respect to $t$ can be expressed as:\n",
    "$$\\dfrac{\\partial h}{\\partial t} = \\dfrac{\\partial h}{\\partial u}\\dfrac{\\partial u}{\\partial t}.$$\n",
    "If the function is expressed as a combination of multiple variables that are expressed in terms of t, i.e. $h(u(t), v(t))$, the the derivative of $h$ with respect to $t$ can be expressed as:\n",
    "$$\\frac{\\partial h}{\\partial t} = \\frac{\\partial h}{\\partial u}\\frac{\\partial u}{\\partial t} + \\frac{\\partial h}{\\partial v}\\frac{\\partial v}{\\partial t}$$\n",
    "\n",
    "Note that we are only looking at scalar variables in this case, but this idea can be extended to vector variables as well.\n",
    "\n",
    "  For any $h\\left(y\\left(x\\right)\\right)$ where $y\\in\\mathbb{R}^{n}$ and $x\\in\\mathbb{R}^{m}$,\n",
    "  \n",
    "  \\begin{align}\n",
    "    \\nabla_{x}h = \\sum_{i=1}^{n}{\\frac{\\partial h}{\\partial y_{i}}\\nabla y_{i}\\left(x\\right)}.\n",
    "  \\end{align}\n",
    "\n",
    "### 4. The graph structure of calculations and forward accumulation\n",
    "\n",
    "Forward accumulation is computing the derivative using the chain rule starting from the inner most derivative to the outer most derivative, where we assume the most basic variables have seed values. Using a graph helps visualize forward accumulation. For example,\n",
    "\n",
    "\\begin{align}\n",
    " f\\left(x,y\\right) &= \\frac{x}{y} +cos(x)sin(y)\\\\\n",
    " x &= y = 1\n",
    "\\end{align}\n",
    "\n",
    " \n",
    "![](img/graph_eg.png)\n",
    "\n",
    "| Trace | Elementary Function | Current Value | Elementary Function Derivative | &nbsp; &nbsp; $\\nabla_{x}$ Value &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp; &nbsp; $\\nabla_{y}$ Value &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "| :---: | :-----------------: | :-----------: | :----------------------------: | :-----------------: | :-----------------: | :-----------------: |\n",
    "| $w_{1}$ | $1$ | $1$ | $\\dot{w_1}$ | $1$ | $0$ |\n",
    "| $w_{2}$ | $1$ | $1$ | $\\dot{w_2}$ | $0$ | $1$ |\n",
    "| $w_{3}$ | $cos{(w_1})$ | $cos{(1)}$ | $-sin{(w_1)}\\dot{w_1}$ | $-sin(1)$ | $0$ |\n",
    "| $w_{4}$ | $sin{(w_2})$ | $sin{(1)}$ | $cos{(w_2)}\\dot{w_2}$ | $0$ | $cos{(1)}$ |\n",
    "| $w_{5}$ | $w_3\\dot w_4$ | $sin{(1)}cos{(1)}$ | $w_4\\dot{w_3} + w_3\\dot{w_4}$ | $-sin^2{(1)}$ | $cos^2{(1)}$ |\n",
    "| $w_{6}$ | $w_1 / w_2$ | $1$ | $\\dot{w_1}/w_2 - w_1 \\dot{w_2}/ w_2^2$ | $1$ | $-1$ |\n",
    "| $w_{7}$ | $w_5 + w_6$ | $sin{(1)}cos{(1)} + 1$ | $\\dot{w_5} + \\dot{w_6}$ | $-sin^2{(1)} + 1$ | $cos^2{(1)}-1$ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7df0AYzM5pL-"
   },
   "source": [
    "# Software Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CuVg_pPY5pMB"
   },
   "source": [
    "The directory structure would look like that:      \n",
    " \n",
    " ```\n",
    " autodiff\\\n",
    "          autodiff\\\n",
    "                    __init__.py\n",
    "                    functions.py\n",
    "                    scalar.py\n",
    "          tests\\\n",
    "                    test_functions.py\n",
    "                    test_scalar.py \n",
    "          docs\\\n",
    "                    milestone1.ipynb\n",
    "                    milestone2.ipynb\n",
    "          README.md\n",
    "          requirements.txt\n",
    "          setup.cfg\n",
    "          LICENSE\n",
    "               \n",
    " ```   \n",
    "\n",
    "Basic modules and what they do?\n",
    "\n",
    "\n",
    "This module aims to compute forward automatic differentiation. The module we implemented can efficiently compute the derivatives of a function of automatic differentiation of a scalar input. The *scalar.py* contains the objects which compute the scalar variables returning the value and the derivative. The dunder methods add, sub, mul, truediv, pow, iadd, isub, imul, idiv, ipow are implemented in this module. The function.py contains sine,cosine,exp functions. Both scalar.py and function.py return the value and the derivative.\n",
    "\n",
    "Where do tests live? How are they run? How are they integrated? \n",
    "\n",
    "\n",
    "We are using both `TravisCI` and `Coveralls` to test our module. Each test function exists in the tests folder, and it utilizes the pytest package.\n",
    "\n",
    "   \n",
    "\n",
    "How can someone install your package? (describe how someone can download and install your package manually)\n",
    "\n",
    "  \n",
    "We are planning to release our package in `PyPI`, but havent done it. Therefore, people can download our software at https://github.com/cs207FinalProjectGroup/cs207-FinalProject.git."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t1BepQX05pME"
   },
   "source": [
    "# Implementation Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o2x4oG0p5pMJ"
   },
   "source": [
    "## Current Implementation\n",
    "\n",
    "\n",
    "We have so far implemented the *Scalar* class, which represents scalar variables. To initialize a *Scalar* class object, the user will pass in a string that represents the variable (i.e. 'x', 'y', 'x1', etc.) and also the value of variable (the seed value). The *Scalar* class holds two attributes: 1) the value of the variable `_val` at the current step and 2) a dictionary `_deriv` containing the derivative or partial derivatives (keys will be the names of the variables (i.e *x* and *y*) and the values will be the derivative value with respect to each variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJY3EJbh5pMM",
    "outputId": "4272ea53-2d89-4301-c4cc-803898af22c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n",
      "{'x': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import autodiff as ad\n",
    "\n",
    "x = ad.Scalar('x',2);\n",
    "print(x._val);\n",
    "print(x._deriv);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CyaOFePD5pMh"
   },
   "source": [
    "Storing the partial derivatives with respect to each variable allows us to easily compute additional derivatives with respect to each variable when we are performing mathematical operations because we can update each partial derivative individually. When a *Scalar* object is initialized, by default `_deriv` will just be a dictionary with the only key being the string the user passes in with value 1. A user can access the value of a *Scalar* object using the *getValue()* method and access the derivative (or partial derivatives) for the object through the *getDeriv()* method. The user can also get the derivatives/partial derivatives as a numpy array with the *getGradient()* method, which takes in a list of strings, with each element representing the variable to take the derivative with respect to, as an argument. \n",
    "\n",
    "The dunder methods __add__, __sub__, __mul__,  __truediv__, __pow__, __iadd__, __isub__, __imul__, __itruediv__, __ipow__ (and the right equivalents for the ones that have one) have been overwritten so that they return a new *Scalar* object with an updated value and derivatives. Thus, the adding or substracting two Scalars or raising a Scalar to the power of another Scalar does not change the values or derivatives of the original Scalar objects. By overwriting these methods, we are implementing forward accumulation, as the orders of operation allows us to traverse the chainrule starting from the inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jPmYsEa5pMk",
    "outputId": "1a5dec08-8bf4-4240-dcaa-a8aaa768f942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "2.0 , 5.0\n"
     ]
    }
   ],
   "source": [
    "#addition example\n",
    "x,y = ad.Scalar('x', 2),ad.Scalar('y', 5);\n",
    "val = x+y;\n",
    "print(val.getValue()); #should be 7.0\n",
    "print(val.getDeriv()['x']); #should be 1.0\n",
    "print(val.getDeriv()['y']); #should be 1.0\n",
    "print();\n",
    "print(x.getValue(),',', y.getValue()); #x, y should retain original values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToV1H5HX5pMx",
    "outputId": "a8d88f06-b049-4c5d-a5e7-dd2ca707b6e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "#pow example\n",
    "x=ad.Scalar('x', 2);\n",
    "val = x**2;\n",
    "print(val.getValue()) #should be 4.0\n",
    "print(val.getDeriv()['x']) #should be 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "55RW4-oU5pM6",
    "outputId": "c5013001-889e-437c-c8c5-95dcfff79ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n",
      "0.5\n",
      "-0.75\n",
      "\n",
      "3.0 , 2.0\n"
     ]
    }
   ],
   "source": [
    "#division example\n",
    "x,y=ad.Scalar('x', 3),ad.Scalar('y', 2);\n",
    "val = x/y;\n",
    "print(val.getValue()) # should be 1.5\n",
    "print(val.getDeriv()['x']); #should be 0.5\n",
    "print(val.getDeriv()['y']); #should be -0.75\n",
    "print();\n",
    "print(x.getValue(),',', y.getValue()); #x, y should retain original values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuJ0x_r-5pNC"
   },
   "source": [
    "We have also implemented the functions **sin**, **cos**, **tan**, **power**, and **exp**. All of these functions can take in an `int`, `float`, or *Scalar* object. If only an `int`/`float` is provided, then a `float` is returned, but if *Scalar* object is provided, then a new *Scalar* object. No changes are made to the value or derivatives of the original *Scalar* object passed in. Within these functions, the *numpy* functions *sin*, *cos*, *tan* and *exp* are used to calculate the appropriate values. <br/>\n",
    "\n",
    "The trigonometric functions  **sin(x)**, **cos(x)**, and **tan(x)** each take in an `int`, `float`, or *Scalar* object *x* and apply the respective trigonometric function to the *x*. If a *x* is a *Scalar* object, the trigonometric function is applied to the *x._val* attribute and the derivative(s) is updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "CxezEuU75pNK",
    "outputId": "998df1fa-181a-4d52-ae7f-06b9f86b3809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092974268256817\n",
      "-0.4161468365471424\n",
      "1.0\n",
      "-0.0\n",
      "-2.185039863261519\n",
      "5.774399204041917\n"
     ]
    }
   ],
   "source": [
    "import autodiff as ad\n",
    "import numpy as np \n",
    "\n",
    "# Sine functions\n",
    "x = ad.Scalar('x', 2.0) # float input \n",
    "val = ad.sin(x)\n",
    "print(val.getValue()); #shoud be 0.90929742682\n",
    "print(val.getDeriv()['x']); #should be -0.41614683654\n",
    "\n",
    "\n",
    "# Cosine functions\n",
    "x = ad.Scalar('x', 0) # integer input \n",
    "val = ad.cos(x)\n",
    "print(val.getValue()); #should be 1.0\n",
    "print(val.getDeriv()['x']); #should be 0.0\n",
    "\n",
    "# tan function\n",
    "x = ad.Scalar('x', 2.0); # float input \n",
    "val = ad.tan(x);\n",
    "print(val.getValue()); #shoudl be -2.185039863261519\n",
    "print(val.getDeriv()['x']); #should be 5.7743992040419174"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NNaQ_4oY5pNP"
   },
   "source": [
    "The **power(x1, x2)** function raises *x1* to the power of *x2*. *x1* and *x2* can be any combination of `ints`, `floats`, or *Scalar* objects. If only ints and floats are provided, then *power* will return a `float` with value *x1* raised to the power of *x2*. If at least one *Scalar* object is provided, then **power** works just like using the **__pow__** operator and returns a new *Scalar* object without changing any values in the original *Scalar* object(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfTnchWP5pNR",
    "outputId": "8beafacd-df54-4677-b5fa-bb99156c548d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125.0\n"
     ]
    }
   ],
   "source": [
    "#power example\n",
    "x = 5.0\n",
    "p = 3.0\n",
    "print (ad.power(x, p)) # should be 125.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NEIwIs4J5pNW"
   },
   "source": [
    "The **exp(x)** function raises *e* to the power of *x* , where *x* can be an `int`, `float`, or *Scalar* object. If *x* is an `int` or `float`, then a `float` with value equal to *e* raised to the power of *x* is returned. If *x* is a Scalar object, then a new *Scalar* is returned with an updated value and derivative(s). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "id": "52nEL7ix5pNX",
    "outputId": "257ee32c-28bb-4b27-89f9-a85790f88a1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "#exponential example\n",
    "x = 1.0\n",
    "print (ad.exp(x)) # should be 2.718281828459045"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X31uNbPq5pNe"
   },
   "source": [
    "## Future plans\n",
    "\n",
    "We still need to implement the Vector class, which will be composed of Scalar objects. \n",
    "\n",
    "For now, we think that our implementation will be something like this:\n",
    "\n",
    "*Vector* will take in a list or array of *Scalar* objects. A *Vector* only has one attribute: a numpy array of *Scalar* objects, since each *Scalar* object will track its current value and derivative. The dunder methods __add__, __sub__, __mul__,  __truediv__, __pow__, __iadd__, __isub__, __imul__, __idiv__, __ipow__ (and the right equivalents) will all be overwritten so that they return a new array of *Scalar* objects with updates values and derivatives. Similar to numpy methods, the operations are conducted element-wise, i.e. In an addition operation between two *Vector* objects, the first row is added to the first row, second row is added to the second row, etc. As a result, one vector operation becomes multiple scalar operations. To access the values in the *Vector* object, the user can use the *getValue()* method, which returns a *numpy.array* of values. To access the derivatives in the *Vector* object, the user can use the *getDeriv()* method, which returns a list of dictionaries containing derivatives or partial derivatives for each *Scalar* object in the array. We can also add a function that returns this as a matrix, which is the Jacobian and add an optional argument to this function such that the user can just get the derivatives or partial derivatives with respect to the desired variables only (i.e. with respect to 'x', with respect to 'y', etc.). The user can obtain a copy of the *numpy.array* with *Scalar* objects using the *getVector()* method, which will return a copy of the *numpy.array* to the user.\n",
    "\n",
    "Likewise, for the functions that we have implemented, we have only implemented them to account for Scalars, but not Vectors, so we need to implement them to take into account Vectors.\n",
    "\n",
    "We will also implement Newton's method for higher dimensions with usage examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-qSq1PRI5pNf"
   },
   "source": [
    "# Citations\n",
    "1. Sondak, David. “Automatic Differentiation: The Basics.” CS207-Lecture9. Cambridge, MA. 2 October 2018.\n",
    "\n",
    "2. Hoffman, Philipp H.W. “A Hitchhiker’s Guide to Automatic Differentiation.” *Numerical Algorithms*, 72, 24 October 2015, 775-811, *Springer Link*, DOI 10.1007/s11075-015-0067-6. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "milestone2_final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
